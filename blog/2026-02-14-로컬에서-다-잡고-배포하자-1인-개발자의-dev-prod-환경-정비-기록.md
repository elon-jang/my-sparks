---
tags: [devops, docker, python, ci-cd]
---

# 로컬에서 다 잡고 배포하자 — 1인 개발자의 dev/prod 환경 정비 기록

> "로컬에서는 되는데요..." — 이 말을 반복하지 않기 위한 환경 정비 기록.

## 배경

1인 개발 프로젝트 [Contents Hub](https://github.com/elon-jang/contents-hub)를 운영하면서, 개발 환경에서 잘 되던 것이 운영에서 터지는 일이 반복됐다. LESSONS.md에 쌓인 89개의 교훈 중 상당수가 dev/prod 환경 차이에서 비롯됐다.

더 이상 운영에서 터진 후 고치는 게 아니라, **로컬에서 모든 형상 변경을 검증하고 배포하는 프로세스**를 세우기로 했다.

## 분석: 어디서 갭이 생기나

개발과 운영 환경을 꼼꼼히 비교해보니 갭이 꽤 많았다. 전부 나열하면 끝이 없으니, **실제로 사고가 났거나 날 수 있는 것**만 추렸다.

### 1. Python 버전 불일치 (3.11 vs 3.12)

Dockerfile은 `python:3.11-slim`, 로컬 venv는 3.12. `datetime.utcnow()` deprecation 같은 런타임 차이가 조용히 숨겨지고 있었다. 3.12 전용 문법을 썼다면 운영에서 바로 터졌을 것이다.

### 2. 의존성이 빌드할 때마다 달라짐

`requirements.txt`에 `fastmcp>=2.0`, `google-genai>=1.0.0` 같은 범위 지정이 있어서, 빌드 시점에 따라 다른 버전이 설치됐다. 이미 두 번 당했다:

- **Lesson #72**: `fastmcp>=2.0` 설치 시 starlette이 0.35→0.52로 올라가면서 FastAPI와 충돌
- **Lesson #79**: httpx 0.28로 올라가면서 anthropic SDK가 `proxies` 파라미터 없다고 크래시

### 3. `create_all`이 마이그레이션 누락을 숨김

SQLAlchemy의 `Base.metadata.create_all()`은 새 테이블을 만들지만, **기존 테이블에 컬럼을 추가하지 않는다**. 개발 환경에서는 DB를 자주 날리니까 문제가 안 보이는데, 운영 DB는 기존 테이블이 그대로 있으니 새 컬럼이 없어서 크래시. Lesson #70, #80에서 같은 실수를 두 번 했다.

### 4. 모델명 하드코딩

`digest.py`에 `model="gemini-2.5-flash"`가 박혀있었다. Lesson #81에서 gemini-2.0-flash의 deprecation 예고를 발견했을 때, 모델 교체에 코드 배포가 필요하다는 걸 깨달았다.

## 결정: 전부 하지 않는다

9개 갭을 찾았지만, 전부 고치는 건 오버엔지니어링이다. 1인 개발에서 ROI 기준으로 걸렀다.

### 지금 하는 것 (3+2)

| 항목 | 이유 | 비용 |
|------|------|------|
| **Dockerfile 3.12** | 가장 근본적인 차이 제거 | 한 줄 |
| **requirements.lock** | 두 번 당한 시한폭탄 | pip-compile 한 번 |
| **Docker smoke test** | 빌드 후 import 검증 | deploy.sh에 한 줄 |
| Gemini 모델 환경변수화 | 5분이면 끝 | config.py + digest.py |
| .env.example 완성 | 누락 변수 3개 | 3줄 추가 |

### 안 하는 것

- **`create_all` 제거**: deploy.sh에 이미 마이그레이션 자동 감지가 있고, 제거하면 개발 마찰만 늘어남
- **통합 테스트를 배포 게이트에 넣기**: 단위 187개가 충분한 게이트 역할. 통합은 의심될 때 수동으로
- **컨테이너 리소스 제한**: VM이 죽은 적 없으면 아직 불필요
- **배포 롤백 자동화**: 배포 빈도 낮고 수동 롤백 명령이 문서화되어 있음

## 구현

### Dockerfile: 3.11 → 3.12

```dockerfile
# Before
FROM python:3.11-slim

# After
FROM python:3.12-slim
```

### Lock 파일 도입

```bash
# requirements.txt (사람이 편집하는 범위 지정)
fastapi>=0.115.0
google-genai>=1.0.0

# pip-compile로 고정
pip-compile --output-file=requirements.lock requirements.txt

# Dockerfile (lock 파일로 설치)
COPY requirements.lock .
RUN pip install --no-cache-dir -r requirements.lock
```

이제 `requirements.txt`는 "무엇을 원하는지", `requirements.lock`은 "정확히 무엇을 설치하는지"가 분리됐다. 패키지 추가 워크플로우:

```
requirements.txt에 추가 → pip-compile → requirements.lock 갱신 → 커밋
```

### deploy.sh: Smoke Test

기존에는 `docker buildx build --push`로 빌드와 푸시가 한 번에 됐다. 이걸 분리해서 중간에 smoke test를 넣었다:

```bash
# Build (로컬에 로드)
docker buildx build --platform linux/amd64 \
    -t "$IMAGE:$VERSION" --load .

# Smoke test
docker run --rm "$IMAGE:$VERSION" \
    python -c "from app.main import app; print('OK')"

# Push (검증 후)
docker push "$IMAGE:$VERSION"
docker push "$IMAGE:latest"
```

이러면 Lesson #68(의존성 누락을 운영에서 발견) 같은 사고를 빌드 단계에서 잡는다.

### 최종 배포 플로우

```
[로컬 Mac]                    [GHCR]                     [운영 VM]
    │                           │                           │
    │ 1. pytest                 │                           │
    │ 2. docker buildx (load)   │                           │
    │ 3. smoke test (import)    │                           │
    │ 4. docker push ──────────▶│                           │
    │                           │◀───── 5. docker pull ─────│
    │                           │                           │
    │                           │       6. alembic migrate  │
    │                           │       7. docker-compose   │
    │                           │          up -d            │
```

## 보너스: 통합 테스트가 깨져있었다

배포 플로우 개선 후 통합 테스트를 돌려보니... 12개 전부 실패. `embed_contents` 컬럼이 테스트 DB에 없었다.

원인은 앞서 분석한 `create_all` 문제의 거울상이었다. 모델에 컬럼을 추가했지만, 테스트 DB는 이미 존재하는 테이블이라 `create_all`이 새 컬럼을 추가하지 않은 것이다.

```python
# Before: 기존 테이블에 새 컬럼을 추가하지 않음
async with engine.begin() as conn:
    await conn.run_sync(Base.metadata.create_all)

# After: 매 테스트마다 깨끗하게 재생성
async with engine.begin() as conn:
    await conn.execute(text("CREATE EXTENSION IF NOT EXISTS vector"))
    await conn.run_sync(Base.metadata.drop_all)
    await conn.run_sync(Base.metadata.create_all)
```

pgvector extension을 `drop_all` 전에 보장해야 한다는 것도 포인트. 테이블을 지우면 vector 타입이 사라져서 `create_all`이 실패한다.

## 교훈

1. **전부 고치지 않는다**. ROI로 거른다. 1인 개발에서 "해야 할 것"과 "하면 좋은 것"의 차이는 크다.
2. **같은 실수 2번은 문서화, 3번은 자동화**. Lesson #70(마이그레이션 누락)은 문서화로 안 됐고, Lesson #80에서 deploy.sh 자동화로 해결됐다.
3. **Lock 파일은 Day 1부터**. "나중에 문제 생기면 하지" → 문제가 생기면 이미 의존성 그래프가 엉켜있어서 풀기가 더 어렵다.
4. **환경 차이는 줄일수록 좋다**. Python 3.11 vs 3.12, 한 버전 차이가 조용히 숨기는 버그는 찾기가 가장 어렵다.

---

*이 글은 Contents Hub 프로젝트의 개발/운영 환경 정비 과정을 기록한 것입니다.*
